
\begin{abstract}
We present an evaluation of the performance that different topic models achieve when applied to the problem of supervised word-sense Disambiguation (WSD). Our algorithm was tested on the SensEval-3 English lexical sample task, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) at different dimensionalities, as well as the Hirearchical Dirichlet Process (HDP). All models were trained on the entire Wikipedia corpus, and applied in a variant on the Lesk algorithm. Our approach is based on selecting the word sense that most often occurs in the top \emph{k} most similar training instances. \\\\
Our results are on par with those of many of the entries to the SensEval-3 evaluation exercise. We found LSA at 350 topics (\emph{k = 12}) to perform best (\emph{recall 0.64}), with LSA generally outperforming LDA, and both outperforming HDP, which could not be properly evaluated partially due to time contraints.\\
\end{abstract}
