\subsection{Latent Dirichlet Allocation}

Latent Dirichlet Allocation (LDA) is another and (arguably) slightly more sophisticated way of automatically discovering topics in text. In contrast to LSA, LDA is a generative model that represents each document as a mixture of a small number of topics where each word in a document exists because it was generated by one of the document's topics. More specifically, LDA assumes that each document is generated in the following fashion:\\

\begin{enumerate}
    \item Determine the number of words $N$ in the document according to some probability distribution (e.g. Poisson).
    \item Select a mixture of $k$ topics for the document according to a Dirichlet distribution. Due to the lack of other evidence all $k$ parameters $\alpha_{i}$ of the distribution are set to the same $\alpha$.
    \item For each topic choose another parameter $\beta$ for the Dirlichet prior of the word distribution.
    \item Finally, generate each word by first picking a topic according to the multinomial distribution (as given by the chosen Dirichlet distribution) and second by using the topic's multinomial distribution to generate the word itself.\\
\end{enumerate}

Assuming this generative model, LDA then tries to backtrack from the documents to find the $k$ topics that have generated the document. More specifically, it tries to find the before mentioned multinomial distributions using Bayesian inference techniques such as Gibbs sampling and expectation propagation. 
